/* auto-generated by NAPI-RS */
/* eslint-disable */
/**
 * ACT-R Memory Model Native Implementation
 *
 * Use cases:
 * - Predict word forgetting curves
 * - Calculate optimal review intervals
 * - Long-term memory retention optimization
 */
export declare class ActrMemoryNative {
  /** Create a new ACT-R memory model instance */
  constructor(
    decay?: number | undefined | null,
    threshold?: number | undefined | null,
    noiseScale?: number | undefined | null,
  );
  /**
   * Compute activation: A = ln(Σ w_j · t_j^(-d))
   *
   * # Arguments
   * * `traces` - Memory traces where `timestamp` is the **absolute time** of each review
   * * `current_time` - Current time in seconds (same unit as traces.timestamp)
   *
   * # Note
   * For "seconds ago" format, use `compute_activation_from_seconds_ago` instead.
   *
   * # Returns
   * Activation value (can be -Infinity for empty traces)
   */
  computeActivation(traces: Array<MemoryTrace>, currentTime: number): number;
  /** Compute activation with custom decay rate */
  computeActivationWithDecay(
    traces: Array<MemoryTrace>,
    currentTime: number,
    decay: number,
  ): number;
  /**
   * Compute activation from "seconds ago" format traces (matching TypeScript API)
   *
   * # Arguments
   * * `traces` - Memory traces where `timestamp` represents **seconds ago from now**
   *   (e.g., timestamp=60 means this review happened 60 seconds ago)
   *
   * # Returns
   * Activation value (can be -Infinity for empty traces)
   */
  computeActivationFromSecondsAgo(traces: Array<MemoryTrace>): number;
  /**
   * Compute recall probability: P = 1 / (1 + exp(-(A-τ)/s))
   *
   * # Arguments
   * * `activation` - Activation value
   *
   * # Returns
   * Recall probability [0, 1]
   */
  retrievalProbability(activation: number): number;
  /** Compute recall probability with custom parameters */
  retrievalProbabilityWithParams(activation: number, threshold: number, noiseScale: number): number;
  /**
   * Compute personalized decay rate based on cognitive profile
   *
   * Algorithm:
   * - Higher memory factor → slower decay (better retention)
   * - Higher speed factor → slightly faster decay (shallow encoding)
   * - Higher stability factor → damping toward default value
   *
   * Reference: Pavlik & Anderson (2008) individual differences model
   *
   * # Arguments
   * * `memory_factor` - Memory ability [0, 1]
   * * `speed_factor` - Processing speed [0, 1]
   * * `stability_factor` - Memory stability [0, 1]
   *
   * # Returns
   * Personalized decay rate [0.3, 0.7]
   */
  computePersonalizedDecay(
    memoryFactor: number,
    speedFactor: number,
    stabilityFactor: number,
  ): number;
  /**
   * Compute optimal review interval using binary search
   *
   * Finds the time when recall probability drops to target value.
   *
   * # Arguments
   * * `traces` - Current review traces (in "seconds ago" format)
   * * `target_probability` - Target recall probability (e.g., 0.7 means review at 70%)
   *
   * # Returns
   * Optimal interval in seconds
   */
  computeOptimalInterval(traces: Array<MemoryTrace>, targetProbability: number): number;
  /** Compute optimal interval with custom decay rate */
  computeOptimalIntervalWithDecay(
    traces: Array<MemoryTrace>,
    targetProbability: number,
    decay: number,
  ): number;
  /** Compute full activation result (base, with noise, and probability) */
  computeFullActivation(traces: Array<MemoryTrace>): ActivationResult;
  /** Compute full activation with custom decay */
  computeFullActivationWithDecay(traces: Array<MemoryTrace>, decay: number): ActivationResult;
  /** Compute recall prediction with confidence */
  predictRecall(traces: Array<MemoryTrace>): RecallPrediction;
  /** Predict optimal review interval with min/max suggestions */
  predictOptimalInterval(
    traces: Array<MemoryTrace>,
    targetRecall?: number | undefined | null,
  ): IntervalPrediction;
  /**
   * Batch compute activations using parallel processing (Rayon)
   *
   * Efficiently processes multiple memory trace sets in parallel.
   *
   * # Arguments
   * * `inputs` - Vector of batch computation inputs
   *
   * # Returns
   * Vector of batch computation results
   */
  batchComputeActivations(inputs: Array<BatchComputeInput>): Array<BatchComputeResult>;
  /** Batch compute activations from "seconds ago" format using parallel processing */
  batchComputeActivationsFromSecondsAgo(
    traceSets: Array<Array<MemoryTrace>>,
  ): Array<BatchComputeResult>;
  /** Batch compute optimal intervals using parallel processing */
  batchComputeOptimalIntervals(
    traceSets: Array<Array<MemoryTrace>>,
    targetProbability: number,
  ): Array<number>;
  /** Get current state */
  getState(): ActrState;
  /** Set state */
  setState(state: ActrState): void;
  /** Update model (increment update count) */
  update(): void;
  /** Reset model */
  reset(): void;
  /** Get decay rate */
  getDecay(): number;
  /** Set decay rate */
  setDecay(decay: number): void;
  /** Get threshold */
  getThreshold(): number;
  /** Set threshold */
  setThreshold(threshold: number): void;
  /** Compute memory strength (normalized activation) */
  computeMemoryStrength(traces: Array<MemoryTrace>): number;
  /**
   * Select action from serialized state and actions
   *
   * This method enables Native-side action selection based on ACT-R memory model principles.
   * The selection is based on:
   * 1. User state (attention, fatigue, motivation, cognitive profile)
   * 2. Available actions with their parameters
   * 3. Context information (session duration, words reviewed)
   *
   * # Arguments
   * * `state` - Serialized user state
   * * `actions` - Serialized action parameters (JSON array string)
   * * `context` - Context information (JSON object string)
   *
   * # Returns
   * Selection result with selected index, score and confidence
   */
  selectActionFromSerialized(
    state: ActrSelectionState,
    actions: string,
    context: ActrSelectionContext,
  ): ActrSelectionResult;
}
export type ACTRMemoryNative = ActrMemoryNative;

/** 因果推断 Native 实现 */
export declare class CausalInferenceNative {
  /** 创建新的因果推断实例 */
  constructor(featureDim: number, config?: CausalInferenceConfig | undefined | null);
  /** 训练倾向得分模型（逻辑回归 + 梯度下降 + L2正则化） */
  fitPropensity(observations: Array<CausalObservation>): void;
  /**
   * 训练结果模型（Ridge回归 + Cholesky分解）
   * 分别训练处理组和对照组模型
   */
  fitOutcome(observations: Array<CausalObservation>): void;
  /** 完整拟合（倾向得分 + 结果模型） */
  fit(observations: Array<CausalObservation>): void;
  /**
   * 计算 AIPW 双重稳健估计
   * 公式: tau = (1/n) * sum[ mu1(X) - mu0(X) + T(Y-mu1(X))/e(X) - (1-T)(Y-mu0(X))/(1-e(X)) ]
   */
  estimateAte(observations: Array<CausalObservation>): CausalEstimate;
  /** Bootstrap 标准误估计（使用 Rayon 并行化） */
  bootstrapSe(
    observations: Array<CausalObservation>,
    nBootstrap?: number | undefined | null,
  ): number;
  /** 诊断倾向得分分布 */
  diagnosePropensity(observations: Array<CausalObservation>): PropensityDiagnostics;
  /** 获取倾向得分（自动添加截距项） */
  getPropensityScore(features: Float64Array): number;
  /** 预测结果（自动添加截距项） */
  predictOutcome(features: Float64Array, treatment: number): number;
  /** 检查是否已拟合 */
  isFitted(): boolean;
  /** 获取特征维度 */
  getFeatureDim(): number;
  /** 重置模型 */
  reset(): void;
}

/** LinUCB 原生实现 */
export declare class LinUcbNative {
  /** 创建新的 LinUCB 实例 */
  constructor(alpha?: number | undefined | null, lambda?: number | undefined | null);
  /** 选择动作（类型化版本，性能更优） */
  selectActionTyped(
    state: UserState,
    actions: Array<ActionTyped>,
    context: LinUCBContext,
  ): ActionSelectionTyped;
  /** 选择动作 */
  selectAction(state: UserState, actions: Array<Action>, context: LinUCBContext): ActionSelection;
  /** 批量选择动作 */
  selectActionBatch(
    states: Array<UserState>,
    actionsList: Array<Array<Action>>,
    contexts: Array<LinUCBContext>,
  ): Array<ActionSelection>;
  /** 更新模型 */
  update(state: UserState, action: Action, reward: number, context: LinUCBContext): void;
  /** 使用 Float64Array 更新（零拷贝） */
  updateWithFloat64Array(featureVec: Float64Array, reward: number): void;
  /** 使用特征向量更新 */
  updateWithFeatureVector(featureVec: Array<number>, reward: number): void;
  /** 批量更新 */
  updateBatch(featureVecs: Array<Array<number>>, rewards: Array<number>): number;
  /** 健康诊断 */
  diagnose(): DiagnosticResult;
  /** 自检 */
  selfTest(): boolean;
  /** 获取模型 */
  getModel(): BanditModel;
  /** 设置模型 */
  setModel(model: BanditModel): void;
  /** 重置模型 */
  reset(): void;
  /** 获取 alpha */
  get alpha(): number;
  /** 设置 alpha */
  set alpha(value: number);
  /** 获取更新计数 */
  get updateCount(): number;
}
export type LinUCBNative = LinUcbNative;

/**
 * Thompson Sampling Native Implementation
 *
 * A context-aware Thompson Sampling algorithm optimized for Rust/NAPI.
 *
 * Usage scenarios:
 * - Efficient exploration during cold-start phase
 * - Binary feedback (correct/incorrect) learning tasks
 * - Scenarios requiring natural exploration-exploitation balance
 */
export declare class ThompsonSamplingNative {
  /** Create a new Thompson Sampling instance with default options */
  constructor();
  /** Create a new instance with custom options */
  static withOptions(options: ThompsonSamplingOptions): ThompsonSamplingNative;
  /** Create a new instance with a specific seed (for testing) */
  static withSeed(seed: number): ThompsonSamplingNative;
  /**
   * Sample from a Beta distribution using Gamma distribution method
   *
   * Uses the property: Beta(alpha, beta) = Gamma(alpha) / (Gamma(alpha) + Gamma(beta))
   */
  sampleBeta(alpha: number, beta: number): number;
  /**
   * Sample from a Gamma distribution using Marsaglia-Tsang method
   *
   * Reference: Marsaglia, G., & Tsang, W. W. (2000).
   * "A simple method for generating gamma variables."
   */
  sampleGamma(shape: number, scale: number): number;
  /**
   * Batch sample from multiple actions
   *
   * Returns sampled values for each action key
   */
  batchSample(actionKeys: Array<string>): Array<number>;
  /** Batch sample with context support */
  batchSampleWithContext(contextKey: string, actionKeys: Array<string>): Array<number>;
  /**
   * Select the best action from a list of action keys
   *
   * Samples from Beta distributions and returns the action with the highest sample value
   */
  selectAction(actionKeys: Array<string>): ActionSelection;
  /**
   * Select the best action with context awareness
   *
   * Blends global and contextual samples based on data availability
   */
  selectActionWithContext(contextKey: string, actionKeys: Array<string>): ActionSelection;
  /**
   * Update parameters based on feedback
   *
   * - success: true -> alpha + 1, false -> beta + 1
   */
  update(actionKey: string, success: boolean): void;
  /**
   * Update parameters with a continuous reward value
   *
   * - Binary mode (default): reward >= 0 -> success, < 0 -> failure
   * - Soft update mode: alpha += (reward + 1) / 2, beta += (1 - reward) / 2
   */
  updateWithReward(actionKey: string, reward: number): void;
  /** Update with context */
  updateWithContext(contextKey: string, actionKey: string, success: boolean): void;
  /** Update with context and continuous reward */
  updateWithContextAndReward(contextKey: string, actionKey: string, reward: number): void;
  /** Batch update multiple actions */
  batchUpdate(updates: Array<BatchUpdateItem>): void;
  /** Get expected value for an action */
  getExpectedValue(actionKey: string): number;
  /** Get expected value with context */
  getExpectedValueWithContext(contextKey: string, actionKey: string): number;
  /** Get sample count for an action (observations excluding prior) */
  getSampleCount(actionKey: string): number;
  /** Get global parameters for an action */
  getGlobalParams(actionKey: string): BetaParams | null;
  /** Get contextual parameters */
  getContextParams(actionKey: string, contextKey: string): BetaParams | null;
  /** Set global parameters directly */
  setGlobalParams(actionKey: string, alpha: number, beta: number): void;
  /** Set contextual parameters directly */
  setContextParams(actionKey: string, contextKey: string, alpha: number, beta: number): void;
  /** Get all global stats */
  getAllStats(): Record<string, BetaParams>;
  /** Get update count */
  getUpdateCount(): number;
  /** Reset all parameters */
  reset(): void;
  /** Get serializable state for persistence */
  getState(): ThompsonSamplingState;
  /** Restore state from serialized data */
  setState(state: ThompsonSamplingState): void;
  /** Set random seed (for testing) */
  setSeed(seed: number): void;
}

/** Action 结构体 */
export interface Action {
  wordId: string;
  difficulty: string;
  scheduledAt?: number;
}

/** Action selection result */
export interface ActionSelection {
  /** Selected action key */
  actionKey: string;
  /** Selection score (sampled value) */
  score: number;
  /** Confidence level [0, 1] */
  confidence: number;
  /** Global sample value */
  globalSample: number;
  /** Contextual sample value */
  contextualSample: number;
}

/** ActionSelection 结构体 - 动作选择结果 */
export interface ActionSelection {
  selectedIndex: number;
  selectedAction: Action;
  exploitation: number;
  exploration: number;
  score: number;
  allScores: Array<number>;
}

/** ActionSelectionTyped 结构体 - 类型化动作选择结果 */
export interface ActionSelectionTyped {
  selectedIndex: number;
  selectedAction: ActionTyped;
  exploitation: number;
  exploration: number;
  score: number;
  allScores: Array<number>;
}

/** Action 类型化版本 */
export interface ActionTyped {
  wordId: string;
  difficulty: Difficulty;
  scheduledAt?: number;
}

/** Activation computation result */
export interface ActivationResult {
  /** Base activation (without noise) */
  baseActivation: number;
  /** Activation with noise */
  activation: number;
  /** Recall probability */
  recallProbability: number;
}

/** Context for action selection */
export interface ActrSelectionContext {
  /** Current time (timestamp) */
  currentTime: number;
  /** Session duration in milliseconds */
  sessionDuration: number;
  /** Number of words reviewed in session */
  wordsReviewed: number;
}

/** Action selection result */
export interface ActrSelectionResult {
  /** Selected action index */
  selectedIndex: number;
  /** Selection score */
  score: number;
  /** Confidence level [0, 1] */
  confidence: number;
  /** Optional metadata (JSON string) */
  metadata?: string;
}

/** User state for action selection */
export interface ActrSelectionState {
  /** Attention level [0, 1] */
  attention: number;
  /** Fatigue level [0, 1] */
  fatigue: number;
  /** Motivation level [-1, 1] */
  motivation: number;
  /** Confidence level [0, 1] */
  conf: number;
  /** Timestamp */
  ts: number;
  /** Memory factor [0, 1] */
  mem: number;
  /** Speed factor [0, 1] */
  speed: number;
  /** Stability factor [0, 1] */
  stability: number;
}

/** ACT-R model state */
export interface ActrState {
  /** Decay rate d (default 0.5) */
  decay: number;
  /** Recall threshold τ */
  threshold: number;
  /** Noise scale s */
  noiseScale: number;
  /** Update count */
  updateCount: number;
}

/** BanditModel 结构体 (字段命名与 TS 对齐) */
export interface BanditModel {
  aMatrix: Array<number>;
  b: Array<number>;
  lMatrix: Array<number>;
  lambda: number;
  alpha: number;
  d: number;
  updateCount: number;
}

/** Batch computation input */
export interface BatchComputeInput {
  /** Traces for this computation */
  traces: Array<MemoryTrace>;
  /** Current time for this computation */
  currentTime: number;
}

/** Batch computation result */
export interface BatchComputeResult {
  /** Activation value */
  activation: number;
  /** Recall probability */
  recallProbability: number;
}

/** Batch update item */
export interface BatchUpdateItem {
  actionKey: string;
  success: boolean;
}

/** Beta distribution parameters */
export interface BetaParams {
  /** Success count (alpha >= 0) */
  alpha: number;
  /** Failure count (beta >= 0) */
  beta: number;
}

/** 因果效应估计结果 */
export interface CausalEstimate {
  /** 平均处理效应 */
  ate: number;
  /** 标准误 */
  standardError: number;
  /** 95% 置信区间下限 */
  confidenceIntervalLower: number;
  /** 95% 置信区间上限 */
  confidenceIntervalUpper: number;
  /** 样本量 */
  sampleSize: number;
  /** 有效样本量（IPW加权后） */
  effectiveSampleSize: number;
  /** p值 */
  pValue: number;
  /** 是否显著（alpha=0.05） */
  significant: boolean;
}

/** 因果推断配置 */
export interface CausalInferenceConfig {
  /** 倾向得分截断下限 */
  propensityMin?: number;
  /** 倾向得分截断上限 */
  propensityMax?: number;
  /** 学习率 */
  learningRate?: number;
  /** 正则化系数 */
  regularization?: number;
  /** 最大迭代次数 */
  maxIterations?: number;
  /** 收敛阈值 */
  convergenceThreshold?: number;
}

/** 因果观测数据 */
export interface CausalObservation {
  /** 特征向量 */
  features: Array<number>;
  /** 处理组标记 (0 或 1) */
  treatment: number;
  /** 结果值 */
  outcome: number;
  /** 时间戳（可选） */
  timestamp?: number;
  /** 用户ID（可选） */
  userId?: string;
}

/** Cognitive profile for personalized decay rate */
export interface CognitiveProfile {
  /** Memory factor [0, 1], higher means better memory */
  memoryFactor: number;
  /** Speed factor [0, 1], higher means faster processing */
  speedFactor: number;
  /** Stability factor [0, 1], higher means more stable memory */
  stabilityFactor: number;
}

/** Compute activation (standalone function) */
export declare function computeActivation(
  traces: Array<MemoryTrace>,
  decay?: number | undefined | null,
): number;

/** Compute optimal interval (standalone function) */
export declare function computeOptimalInterval(
  traces: Array<MemoryTrace>,
  targetProbability: number,
  decay?: number | undefined | null,
  threshold?: number | undefined | null,
  noiseScale?: number | undefined | null,
): number;

/** Compute recall probability (standalone function) */
export declare function computeRecallProbability(
  activation: number,
  threshold?: number | undefined | null,
  noiseScale?: number | undefined | null,
): number;

/** DiagnosticResult 结构体 - 诊断结果 */
export interface DiagnosticResult {
  isHealthy: boolean;
  hasNan: boolean;
  hasInf: boolean;
  conditionNumber: number;
  minDiagonal: number;
  maxDiagonal: number;
  message: string;
}

/** Difficulty 枚举 */
export declare const enum Difficulty {
  Recognition = 0,
  Recall = 1,
  Spelling = 2,
  Listening = 3,
  Usage = 4,
}

/** 计算冷启动 alpha (独立函数) */
export declare function getColdStartAlpha(
  interactionCount: number,
  recentAccuracy: number,
  fatigue: number,
): number;

/** Optimal interval prediction result */
export interface IntervalPrediction {
  /** Optimal interval (seconds) */
  optimalSeconds: number;
  /** Minimum suggested interval (seconds) */
  minSeconds: number;
  /** Maximum suggested interval (seconds) */
  maxSeconds: number;
  /** Target recall probability */
  targetRecall: number;
}

/** LinUCBContext 结构体 */
export interface LinUcbContext {
  timeOfDay: number;
  dayOfWeek: number;
  sessionDuration: number;
  fatigueFactor?: number;
}

/** Memory trace record */
export interface MemoryTrace {
  /** Time since this review (seconds ago from current time) */
  timestamp: number;
  /** Whether the answer was correct */
  isCorrect: boolean;
}

/** 倾向得分诊断 */
export interface PropensityDiagnostics {
  /** 均值 */
  mean: number;
  /** 标准差 */
  std: number;
  /** 中位数 */
  median: number;
  /** 处理组均值 */
  treatmentMean: number;
  /** 对照组均值 */
  controlMean: number;
  /** 重叠度量 */
  overlap: number;
  /** AUC（区分度） */
  auc: number;
}

/** Recall prediction result */
export interface RecallPrediction {
  /** Activation (typically -2 to 2) */
  activation: number;
  /** Recall probability [0, 1] */
  recallProbability: number;
  /** Prediction confidence [0, 1] */
  confidence: number;
}

/** Thompson Sampling configuration options */
export interface ThompsonSamplingOptions {
  /** Prior alpha (default: 1, uninformative prior) */
  priorAlpha?: number;
  /** Prior beta (default: 1, uninformative prior) */
  priorBeta?: number;
  /** Minimum context weight */
  minContextWeight?: number;
  /** Maximum context weight */
  maxContextWeight?: number;
  /** Enable soft update mode */
  enableSoftUpdate?: boolean;
  /** Random seed for reproducibility (optional) */
  seed?: number;
}

/** Serializable state for persistence */
export interface ThompsonSamplingState {
  /** Version number (for migration) */
  version: string;
  /** Prior alpha */
  priorAlpha: number;
  /** Prior beta */
  priorBeta: number;
  /** Total update count */
  updateCount: number;
  /** Global Beta parameters (JSON serialized) */
  globalParamsJson: string;
  /** Contextual Beta parameters (JSON serialized) */
  contextParamsJson: string;
}

/** UCBStats 结构体 - UCB 统计信息 */
export interface UcbStats {
  theta: Array<number>;
  exploitation: number;
  confidence: number;
  score: number;
}

/** UserState 结构体 */
export interface UserState {
  masteryLevel: number;
  recentAccuracy: number;
  studyStreak: number;
  totalInteractions: number;
  averageResponseTime: number;
}
